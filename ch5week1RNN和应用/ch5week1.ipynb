{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import rnn_utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. 搭建循环神经网络"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rnn_cell_forward(xt, a_prev, parameters):\n",
    "    # 从“parameters”获取参数\n",
    "    Wax = parameters[\"Wax\"]\n",
    "    Waa = parameters[\"Waa\"]\n",
    "    Wya = parameters[\"Wya\"]\n",
    "    ba = parameters[\"ba\"]\n",
    "    by = parameters[\"by\"]\n",
    "    \n",
    "    a_next = np.tanh(np.dot(Wax, xt) + np.dot(Waa, a_prev) + ba)\n",
    "    yt_pred = rnn_utils.softmax(np.dot(Wya, a_next) + by)\n",
    "    \n",
    "    cache = (a_next, a_prev, xt, parameters)\n",
    "    return a_next, yt_pred, cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rnn_forward(x, a0, parameters):\n",
    "    caches = []\n",
    "    \n",
    "    n_x, m, T_x = x.shape\n",
    "    n_y, n_a = parameters['Wya'].shape\n",
    "    a = np.zeros([n_a, m, T_x])\n",
    "    y_pred = np.zeros([n_y, m, T_x])\n",
    "    \n",
    "    a_next = a0\n",
    "    \n",
    "    for t in range(T_x):\n",
    "        a_next, yt_pred, cache = rnn_cell_forward(x[:,:,t], a_next, parameters)\n",
    "        \n",
    "        a[:,:,t] = a_next\n",
    "        y_pred[:,:,t] = yt_pred\n",
    "        caches.append(cache)\n",
    "    \n",
    "    caches = (caches, x)\n",
    "    return a, y_pred, caches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a[4][1] =  [-0.99999375  0.77911235 -0.99861469 -0.99833267]\n",
      "a.shape =  (5, 10, 4)\n",
      "y_pred[1][3] = [0.79560373 0.86224861 0.11118257 0.81515947]\n",
      "y_pred.shape =  (2, 10, 4)\n",
      "caches[1][1][3] = [-1.1425182  -0.34934272 -0.20889423  0.58662319]\n",
      "len(caches) =  2\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(1)\n",
    "x = np.random.randn(3,10,4)\n",
    "a0 = np.random.randn(5,10)\n",
    "Waa = np.random.randn(5,5)\n",
    "Wax = np.random.randn(5,3)\n",
    "Wya = np.random.randn(2,5)\n",
    "ba = np.random.randn(5,1)\n",
    "by = np.random.randn(2,1)\n",
    "parameters = {\"Waa\": Waa, \"Wax\": Wax, \"Wya\": Wya, \"ba\": ba, \"by\": by}\n",
    "\n",
    "a, y_pred, caches = rnn_forward(x, a0, parameters)\n",
    "print(\"a[4][1] = \", a[4][1])\n",
    "print(\"a.shape = \", a.shape)\n",
    "print(\"y_pred[1][3] =\", y_pred[1][3])\n",
    "print(\"y_pred.shape = \", y_pred.shape)\n",
    "print(\"caches[1][1][3] =\", caches[1][1][3])\n",
    "print(\"len(caches) = \", len(caches))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lstm_cell_forward(xt, a_prev, c_prev, parameters):\n",
    "    '''\n",
    "    parameters -- 字典类型的变量，包含了：\n",
    "                Wf -- 遗忘门的权值，维度为(n_a, n_a + n_x)\n",
    "                bf -- 遗忘门的偏置，维度为(n_a, 1)\n",
    "                Wi -- 更新门的权值，维度为(n_a, n_a + n_x)\n",
    "                bi -- 更新门的偏置，维度为(n_a, 1)\n",
    "                Wc -- 第一个“tanh”的权值，维度为(n_a, n_a + n_x)\n",
    "                bc -- 第一个“tanh”的偏置，维度为(n_a, n_a + n_x)\n",
    "                Wo -- 输出门的权值，维度为(n_a, n_a + n_x)\n",
    "                bo -- 输出门的偏置，维度为(n_a, 1)\n",
    "                Wy -- 隐藏状态与输出相关的权值，维度为(n_y, n_a)\n",
    "                by -- 隐藏状态与输出相关的偏置，维度为(n_y, 1)\n",
    "    '''\n",
    "    Wf = parameters[\"Wf\"]\n",
    "    bf = parameters[\"bf\"]\n",
    "    Wi = parameters[\"Wi\"]\n",
    "    bi = parameters[\"bi\"]\n",
    "    Wc = parameters[\"Wc\"]\n",
    "    bc = parameters[\"bc\"]\n",
    "    Wo = parameters[\"Wo\"]\n",
    "    bo = parameters[\"bo\"]\n",
    "    Wy = parameters[\"Wy\"]\n",
    "    by = parameters[\"by\"]\n",
    "\n",
    "    n_x, m = xt.shape\n",
    "    n_y, n_a = Wy.shape\n",
    "    \n",
    "    concat = np.zeros([n_a+n_x, m])\n",
    "    concat[:n_a, :] = a_prev\n",
    "    concat[n_a:, :] = xt\n",
    "    \n",
    "    # 计算遗忘门、更新门、输出门\n",
    "    ft = rnn_utils.sigmoid(np.dot(Wf, concat) + bf)\n",
    "    it = rnn_utils.sigmoid(np.dot(Wi, concat) + bi)\n",
    "    ot = rnn_utils.sigmoid(np.dot(Wo, concat) + bo)\n",
    "    \n",
    "    ct_wave = np.tanh(np.dot(Wc, concat) + bc)\n",
    "    c_next = ft * c_prev + it * ct_wave\n",
    "    a_next = ot * np.tanh(c_next)\n",
    "    yt_pred = rnn_utils.softmax(np.dot(Wy, a_next) + by)\n",
    "    \n",
    "    # 保存包含了反向传播所需要的参数\n",
    "    cache = (a_next, c_next, a_prev, c_prev, ft, it, ct_wave, ot, xt, parameters)\n",
    "    \n",
    "    return a_next, c_next, yt_pred, cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lstm_forward(x, a0, parameters):\n",
    "    caches = []\n",
    "    n_x, m, T_x = x.shape\n",
    "    n_y, n_a = parameters[\"Wy\"].shape\n",
    "    \n",
    "    a = np.zeros([n_a, m, T_x])\n",
    "    c = np.zeros([n_a, m, T_x])\n",
    "    y = np.zeros([n_y, m, T_x])\n",
    "    \n",
    "    a_next = a0\n",
    "    c_next = np.zeros([n_a, m])\n",
    "    \n",
    "    for t in range(T_x):\n",
    "        a_next, c_next, yt_pred, cache = lstm_cell_forward(x[:,:,t], a_next, c_next, parameters)\n",
    "        \n",
    "        a[:,:,t] = a_next\n",
    "        c[:,:,t] = c_next\n",
    "        y[:,:,t] = yt_pred\n",
    "        caches.append(cache)\n",
    "        \n",
    "    # 保存反向传播需要的参数\n",
    "    caches = (caches, x)\n",
    "    \n",
    "    return a, y, c, caches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a[4][3][6] =  0.17211776753291672\n",
      "a.shape =  (5, 10, 7)\n",
      "y[1][4][3] = 0.9508734618501101\n",
      "y.shape =  (2, 10, 7)\n",
      "caches[1][1[1]] = [ 0.82797464  0.23009474  0.76201118 -0.22232814 -0.20075807  0.18656139\n",
      "  0.41005165]\n",
      "c[1][2][1] -0.8555449167181981\n",
      "len(caches) =  2\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(1)\n",
    "x = np.random.randn(3,10,7)\n",
    "a0 = np.random.randn(5,10)\n",
    "Wf = np.random.randn(5, 5+3)\n",
    "bf = np.random.randn(5,1)\n",
    "Wi = np.random.randn(5, 5+3)\n",
    "bi = np.random.randn(5,1)\n",
    "Wo = np.random.randn(5, 5+3)\n",
    "bo = np.random.randn(5,1)\n",
    "Wc = np.random.randn(5, 5+3)\n",
    "bc = np.random.randn(5,1)\n",
    "Wy = np.random.randn(2,5)\n",
    "by = np.random.randn(2,1)\n",
    "\n",
    "parameters = {\"Wf\": Wf, \"Wi\": Wi, \"Wo\": Wo, \"Wc\": Wc, \"Wy\": Wy, \"bf\": bf, \"bi\": bi, \"bo\": bo, \"bc\": bc, \"by\": by}\n",
    "\n",
    "a, y, c, caches = lstm_forward(x, a0, parameters)\n",
    "print(\"a[4][3][6] = \", a[4][3][6])\n",
    "print(\"a.shape = \", a.shape)\n",
    "print(\"y[1][4][3] =\", y[1][4][3])\n",
    "print(\"y.shape = \", y.shape)\n",
    "print(\"caches[1][1[1]] =\", caches[1][1][1])\n",
    "print(\"c[1][2][1]\", c[1][2][1])\n",
    "print(\"len(caches) = \", len(caches))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 循环神经网络的反向传播（略）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 字符级语言模型——恐龙岛"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "import random\n",
    "import cllm_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "共计有19909个字符，唯一字符有27个\n"
     ]
    }
   ],
   "source": [
    "data = open(r\"dinos.txt\", \"r\").read()\n",
    "data = data.lower()\n",
    "chars = list(set(data))\n",
    "\n",
    "data_size, vocab_size = len(data), len(chars)\n",
    "print(\"共计有%d个字符，唯一字符有%d个\"%(data_size,vocab_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'\\n': 0, 'a': 1, 'b': 2, 'c': 3, 'd': 4, 'e': 5, 'f': 6, 'g': 7, 'h': 8, 'i': 9, 'j': 10, 'k': 11, 'l': 12, 'm': 13, 'n': 14, 'o': 15, 'p': 16, 'q': 17, 'r': 18, 's': 19, 't': 20, 'u': 21, 'v': 22, 'w': 23, 'x': 24, 'y': 25, 'z': 26}\n",
      "{0: '\\n', 1: 'a', 2: 'b', 3: 'c', 4: 'd', 5: 'e', 6: 'f', 7: 'g', 8: 'h', 9: 'i', 10: 'j', 11: 'k', 12: 'l', 13: 'm', 14: 'n', 15: 'o', 16: 'p', 17: 'q', 18: 'r', 19: 's', 20: 't', 21: 'u', 22: 'v', 23: 'w', 24: 'x', 25: 'y', 26: 'z'}\n"
     ]
    }
   ],
   "source": [
    "char_to_ix = {ch:i for i, ch in enumerate(sorted(chars))}\n",
    "ix_to_char = {i:ch for i, ch in enumerate(sorted(chars))}\n",
    "\n",
    "print(char_to_ix)\n",
    "print(ix_to_char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clip(gradients, maxValue):\n",
    "    \"\"\"\n",
    "    使用maxValue来修剪梯度\n",
    "    \n",
    "    参数：\n",
    "        gradients -- 字典类型，包含了以下参数：\"dWaa\", \"dWax\", \"dWya\", \"db\", \"dby\"\n",
    "        maxValue -- 阈值，把梯度值限制在[-maxValue, maxValue]内\n",
    "        \n",
    "    返回：\n",
    "        gradients -- 修剪后的梯度\n",
    "    \"\"\"\n",
    "    # 获取参数\n",
    "    dWaa, dWax, dWya, db, dby = gradients['dWaa'], gradients['dWax'], gradients['dWya'], gradients['db'], gradients['dby']\n",
    "    \n",
    "    # 梯度修剪\n",
    "    for gradient in [dWaa, dWax, dWya, db, dby]:\n",
    "        np.clip(gradient, -maxValue, maxValue, out=gradient)\n",
    "\n",
    "    gradients = {\"dWaa\": dWaa, \"dWax\": dWax, \"dWya\": dWya, \"db\": db, \"dby\": dby}\n",
    "    \n",
    "    return gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample(parameters, char_to_ix, seed):\n",
    "    Waa, Wax, Wya, by, b = parameters['Waa'], parameters['Wax'], parameters['Wya'], parameters['by'], parameters['b']\n",
    "    vocab_size, n_a = Wya.shape\n",
    "    \n",
    "    idx_newline = char_to_ix[\"\\n\"]\n",
    "    idx = -1\n",
    "    indices = []\n",
    "    counter = 0\n",
    "    \n",
    "    a_prev = np.zeros((n_a,1))\n",
    "    # 创建独热向量x\n",
    "    x = np.zeros((vocab_size,1))\n",
    "    \n",
    "    while idx != idx_newline and counter < 50:\n",
    "        a = np.tanh(np.dot(Waa,a_prev) + np.dot(Wax,x) + b)\n",
    "        z = np.dot(Wya,a) + by\n",
    "        y = cllm_utils.softmax(z)\n",
    "        \n",
    "        np.random.seed(counter + seed)\n",
    "        idx = np.random.choice(list(range(vocab_size)),p=y.ravel())\n",
    "        indices.append(idx)\n",
    "        \n",
    "        x = np.zeros((vocab_size,1))\n",
    "        x[idx] = 1\n",
    "        a_prev = a\n",
    "        \n",
    "        seed += 1\n",
    "        counter += 1\n",
    "        \n",
    "    if(counter == 50):\n",
    "        indices.append(idx_newline)\n",
    "    return indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampling:\n",
      "list of sampled indices: [12, 17, 24, 14, 13, 9, 10, 22, 24, 6, 13, 11, 12, 6, 21, 15, 21, 14, 3, 2, 1, 21, 18, 24, 7, 25, 6, 25, 18, 10, 16, 2, 3, 8, 15, 12, 11, 7, 1, 12, 10, 2, 7, 7, 11, 17, 24, 12, 3, 1, 0]\n",
      "list of sampled characters: ['l', 'q', 'x', 'n', 'm', 'i', 'j', 'v', 'x', 'f', 'm', 'k', 'l', 'f', 'u', 'o', 'u', 'n', 'c', 'b', 'a', 'u', 'r', 'x', 'g', 'y', 'f', 'y', 'r', 'j', 'p', 'b', 'c', 'h', 'o', 'l', 'k', 'g', 'a', 'l', 'j', 'b', 'g', 'g', 'k', 'q', 'x', 'l', 'c', 'a', '\\n']\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(2)\n",
    "_, n_a = 20, 100\n",
    "Wax, Waa, Wya = np.random.randn(n_a, vocab_size), np.random.randn(n_a, n_a), np.random.randn(vocab_size, n_a)\n",
    "b, by = np.random.randn(n_a, 1), np.random.randn(vocab_size, 1)\n",
    "parameters = {\"Wax\": Wax, \"Waa\": Waa, \"Wya\": Wya, \"b\": b, \"by\": by}\n",
    "\n",
    "\n",
    "indices = sample(parameters, char_to_ix, 0)\n",
    "print(\"Sampling:\")\n",
    "print(\"list of sampled indices:\", indices)\n",
    "print(\"list of sampled characters:\", [ix_to_char[i] for i in indices])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 语言模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize(X, Y, a_prev, parameters,learning_rate=0.01):\n",
    "    \"\"\"\n",
    "    执行训练模型的单步优化。\n",
    "    \n",
    "    参数：\n",
    "        X -- 整数列表，其中每个整数映射到词汇表中的字符。\n",
    "        Y -- 整数列表，与X完全相同，但向左移动了一个索引。\n",
    "        a_prev -- 上一个隐藏状态\n",
    "        parameters -- 字典，包含了以下参数：\n",
    "                        Wax -- 权重矩阵乘以输入，维度为(n_a, n_x)\n",
    "                        Waa -- 权重矩阵乘以隐藏状态，维度为(n_a, n_a)\n",
    "                        Wya -- 隐藏状态与输出相关的权重矩阵，维度为(n_y, n_a)\n",
    "                        b -- 偏置，维度为(n_a, 1)\n",
    "                        by -- 隐藏状态与输出相关的权重偏置，维度为(n_y, 1)\n",
    "        learning_rate -- 模型学习的速率\n",
    "    \n",
    "    返回：\n",
    "        loss -- 损失函数的值（交叉熵损失）\n",
    "        gradients -- 字典，包含了以下参数：\n",
    "                        dWax -- 输入到隐藏的权值的梯度，维度为(n_a, n_x)\n",
    "                        dWaa -- 隐藏到隐藏的权值的梯度，维度为(n_a, n_a)\n",
    "                        dWya -- 隐藏到输出的权值的梯度，维度为(n_y, n_a)\n",
    "                        db -- 偏置的梯度，维度为(n_a, 1)\n",
    "                        dby -- 输出偏置向量的梯度，维度为(n_y, 1)\n",
    "        a[len(X)-1] -- 最后的隐藏状态，维度为(n_a, 1)\n",
    "    \"\"\"\n",
    "    loss,cache = cllm_utils.rnn_forward(X, Y, a_prev, parameters)\n",
    "    \n",
    "    grads, a = cllm_utils.rnn_backward(X, Y, parameters, cache)\n",
    "    \n",
    "    # 梯度修剪\n",
    "    grads = clip(grads, 5)\n",
    "    \n",
    "    parameters = cllm_utils.update_parameters(parameters, grads, learning_rate)\n",
    "    \n",
    "    return loss,grads,a[len(X)-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss = 126.50397572165345\n",
      "gradients[\"dWaa\"][1][2] = 0.19470931534725341\n",
      "np.argmax(gradients[\"dWax\"]) = 93\n",
      "gradients[\"dWya\"][1][2] = -0.007773876032004315\n",
      "gradients[\"db\"][4] = [-0.06809825]\n",
      "gradients[\"dby\"][1] = [0.01538192]\n",
      "a_last[4] = [-1.]\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(1)\n",
    "vocab_size, n_a = 27, 100\n",
    "a_prev = np.random.randn(n_a, 1)\n",
    "Wax, Waa, Wya = np.random.randn(n_a, vocab_size), np.random.randn(n_a, n_a), np.random.randn(vocab_size, n_a)\n",
    "b, by = np.random.randn(n_a, 1), np.random.randn(vocab_size, 1)\n",
    "parameters = {\"Wax\": Wax, \"Waa\": Waa, \"Wya\": Wya, \"b\": b, \"by\": by}\n",
    "X = [12,3,5,11,22,3]\n",
    "Y = [4,14,11,22,25, 26]\n",
    "\n",
    "loss, gradients, a_last = optimize(X, Y, a_prev, parameters, learning_rate = 0.01)\n",
    "print(\"Loss =\", loss)\n",
    "print(\"gradients[\\\"dWaa\\\"][1][2] =\", gradients[\"dWaa\"][1][2])\n",
    "print(\"np.argmax(gradients[\\\"dWax\\\"]) =\", np.argmax(gradients[\"dWax\"]))\n",
    "print(\"gradients[\\\"dWya\\\"][1][2] =\", gradients[\"dWya\"][1][2])\n",
    "print(\"gradients[\\\"db\\\"][4] =\", gradients[\"db\"][4])\n",
    "print(\"gradients[\\\"dby\\\"][1] =\", gradients[\"dby\"][1])\n",
    "print(\"a_last[4] =\", a_last[4])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(data, ix_to_char, char_to_ix, num_iterations=3500, \n",
    "          n_a=50, dino_names=7,vocab_size=27):\n",
    "    \"\"\"\n",
    "    训练模型并生成恐龙名字\n",
    "    \n",
    "    参数：\n",
    "        data -- 语料库\n",
    "        ix_to_char -- 索引映射字符字典\n",
    "        char_to_ix -- 字符映射索引字典\n",
    "        num_iterations -- 迭代次数\n",
    "        n_a -- RNN单元数量\n",
    "        dino_names -- 每次迭代中采样的数量\n",
    "        vocab_size -- 在文本中的唯一字符的数量\n",
    "    \n",
    "    返回：\n",
    "        parameters -- 学习后了的参数\n",
    "    \"\"\"\n",
    "    n_x,n_y = vocab_size,vocab_size\n",
    "    \n",
    "    # 初始化参数\n",
    "    parameters = cllm_utils.initialize_parameters(n_a, n_x, n_y)\n",
    "    \n",
    "    # 初始化损失\n",
    "    losses = []\n",
    "    loss = cllm_utils.get_initial_loss(vocab_size, dino_names)\n",
    "    \n",
    "    with open(\"dinos.txt\") as f:\n",
    "        examples = f.readlines()\n",
    "    examples = [x.lower().strip() for x in examples]\n",
    "    \n",
    "    np.random.seed(0)\n",
    "    np.random.shuffle(examples)\n",
    "    \n",
    "    a_prev = np.zeros((n_a,1))\n",
    "    \n",
    "    for j in range(num_iterations):\n",
    "        index = j % len(examples)\n",
    "        X = [None] + [char_to_ix[ch] for ch in examples[index]]\n",
    "        Y = X[1:] + [char_to_ix[\"\\n\"]]\n",
    "        \n",
    "        curr_loss,grads,a_prev = optimize(X, Y, a_prev, parameters)\n",
    "        \n",
    "        # 使用延迟来保持损失平滑,这是为了加速训练。\n",
    "        loss = cllm_utils.smooth(loss, curr_loss)\n",
    "        losses.append(loss)\n",
    "        \n",
    "        # 每2000次迭代，通过sample()生成“\\n”字符，检查模型是否学习正确\n",
    "        if j % 2000 == 0:\n",
    "            print(\"第\" + str(j+1) + \"次迭代，损失值为：\" + str(loss))\n",
    "            \n",
    "            seed = 0\n",
    "            for name in range(dino_names):\n",
    "                # 采样\n",
    "                sampled_indices = sample(parameters, char_to_ix, seed)\n",
    "                cllm_utils.print_sample(sampled_indices, ix_to_char)\n",
    "                \n",
    "                # 为了得到相同的效果，随机种子+1\n",
    "                seed += 1\n",
    "            \n",
    "            print(\"\\n\")\n",
    "        \n",
    "    import matplotlib.pyplot as plt\n",
    "    plt.plot(np.squeeze(losses))\n",
    "    plt.show()\n",
    "    \n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\tech\\Anaconda3\\envs\\pytorch1.4-cuda10.1\\lib\\site-packages\\ipykernel_launcher.py:2: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "第1次迭代，损失值为：23.087336085484605\n",
      "Nkzxwtdmfqoeyhsqwasjkjvu\n",
      "Kneb\n",
      "Kzxwtdmfqoeyhsqwasjkjvu\n",
      "Neb\n",
      "Zxwtdmfqoeyhsqwasjkjvu\n",
      "Eb\n",
      "Xwtdmfqoeyhsqwasjkjvu\n",
      "\n",
      "\n",
      "第2001次迭代，损失值为：27.884160491415773\n",
      "Liusskeomnolxeros\n",
      "Hmdaairus\n",
      "Hytroligoraurus\n",
      "Lecalosapaus\n",
      "Xusicikoraurus\n",
      "Abalpsamantisaurus\n",
      "Tpraneronxeros\n",
      "\n",
      "\n",
      "第4001次迭代，损失值为：25.90181489335302\n",
      "Mivrosaurus\n",
      "Inee\n",
      "Ivtroplisaurus\n",
      "Mbaaisaurus\n",
      "Wusichisaurus\n",
      "Cabaselachus\n",
      "Toraperlethosdarenitochusthiamamumamaon\n",
      "\n",
      "\n",
      "第6001次迭代，损失值为：24.60877890083239\n",
      "Onwusceomosaurus\n",
      "Lieeaerosaurus\n",
      "Lxussaurus\n",
      "Oma\n",
      "Xusteonosaurus\n",
      "Eeahosaurus\n",
      "Toreonosaurus\n",
      "\n",
      "\n",
      "第8001次迭代，损失值为：24.070350147705284\n",
      "Onxusichepriuon\n",
      "Kilabersaurus\n",
      "Lutrodon\n",
      "Omaaerosaurus\n",
      "Xutrcheps\n",
      "Edaksoje\n",
      "Trodiktonus\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "执行了：0分8秒\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\tech\\Anaconda3\\envs\\pytorch1.4-cuda10.1\\lib\\site-packages\\ipykernel_launcher.py:8: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "#开始时间\n",
    "start_time = time.clock()\n",
    "\n",
    "#开始训练\n",
    "parameters = model(data, ix_to_char, char_to_ix, num_iterations=10000)\n",
    "\n",
    "#结束时间\n",
    "end_time = time.clock()\n",
    "\n",
    "#计算时差\n",
    "minium = end_time - start_time\n",
    "\n",
    "print(\"执行了：\" + str(int(minium / 60)) + \"分\" + str(int(minium%60)) + \"秒\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
